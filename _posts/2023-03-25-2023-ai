---
layout: single
title: "人工智能2023新进展及其思考"
date: 2023-03-25
categories: [ai, article, worldview]
---

<p align="center">
    <img src="/assets/images/2023-03-25/1.png" alt="drawing"/>
</p>


除了上一篇文章，我之前不会根据时事动态写文章。不过最近人工智能的进展实在是太快，且对整个社会的潜在影响力太广泛。

来我家装修的师父，也开始问我知不知道ChatGPT。这个现象让我想起了彼得林奇的鸡尾酒会理论。是不是资本泡沫这这另说，但无论我们是否关注这些进展，长期来看它们都将直接或间接地影响我们生活的方方面面。

这篇文章的讨论的内容包含以下方面：
1. 罗列并简短总结过去2个月人工智能在基础及应用的新进展。
2. 分享一下我对这些新进展产生的底层变革的理解。
3. 讨论人在人工智能逐渐强大的环境下如何适应。

## 近期进展
过去2个月，基本上每天都有人工智能方面的新进展，我相信大多数人包括我面对如此爆炸量的信息都应接不暇。为了方便大家了解，这里我对其中一些进展列了个图表，并对它们做一下简短总结。

### Toolformer
Toolformer是Meta最近发表的一篇文章，该文章描述了一种新型的语言模型，它可以以自我监督的方式学习如何使用各种工具。该模型可以通过学习API调用来提高自身能力，从而使得语言模型从纯粹的文字交流变成具有行动力的机器。

需要注意的是，这里所指的使用工具是模型自动根据训练数据习得的能力，而不是通过外部系统来明确指导模型在什么时候使用什么工具。这与langchain这样的脚手架代码库有本质的不同。

**这项研究的意义在于给语言模型这个大脑建立了与外部世界通信的桥梁，让它们从此有了手脚。**


### PaLM-E
PaLM-E是由Google Robotics，TU Berlin和Google Research提出的一种新的针对机器人的AI模型。它可以帮助机器人理解和推理多种感官信息，从而指导机器人实现更加普适且准确的行为。PaLM-E的实验结果表明，它可以在多种任务中取得出色的性能，包括视觉和语言任务。**这项研究为机器人行为的训练提供了一种新的方向。**

<p align="center">
    <img src="/assets/images/2023-03-25/2.gif" alt="drawing"/>
    <br/><em><strong>这项任务的输入是：Get a chip bag。机器人根据这个输入在干扰下执行了复杂的任务</strong></em>
</p>

相比于波斯顿动力把控制论让机器人的移动发挥至极致的思路，Google从人工智能的方向入手使得训练机器人执行任务效率更高。也许在不久的将来，我们可以有可以通过语音控制的居家机器人。

这两个都是我感兴趣的方向，《[让我们来做一个流浪地球中的MOSS](https://yxjiang.github.io/ai/moss/)

### GPT-4

GPT-4这里就不过多讨论了，网上相关文章不下一万篇，我在《[更强的人工智能：GPT-4抢先用户测评](https://yxjiang.github.io/ai/gpt4/)》也讨论过。

**GPT-4的影响力不在于它相比于GPT-3更强大的语言理解能力，而在于它是长了眼睛的多模态语言模型。** 这种能力可以使得它可以更加全面地理解这个世界。想象一个视力健全的人和一个盲人对世界的了解就能明白这种差距不是靠大力出奇迹就能弥补的。

### Claude
Claud是Anthropic公司开发的语言模型，**这个模型使用了一种被称为“Constitutional AI”的技术，该技术通过人提供的一系列规则或原则而不是标注数据来指导模型进行训练。** 除此之外，算法通过链式推理的自我改进来训练一个无害的人工智能助手，而不需要任何人工标记来识别有害的输出。与ChatGPT相比，这些方法使得训练Claud的算法能够更加精确地控制人工智能的行为，而无需进行大量的人工标记。

<p align="center">
    <img src="/assets/images/2023-03-25/3.png" alt="drawing"/>
</p>

不知道Anthropic制定原则时是否考虑了阿西莫夫的机器人三原则。

<p align="center">
    <img src="/assets/images/2023-03-25/4.png" alt="drawing"/>
</p>

## Microsoft 365 Copilot，Copilot X，以及ChatGPT插件
这三个是应用层面的革新，对某些人来说它们是提升生产力的利器，对另一些人来说它们是自己职业生涯的威胁。

你甚至还可以直接根据这些内容一键生成相应的PPT。同样，对于会议，你可以让AI对会议内容进行总结并在会议结束后直接抄送给所有与会方。

<p align="center">
    <img src="/assets/images/2023-03-25/5.gif" alt="drawing"/>
    <br/><em><strong>根据讨论内容自动总结并抄送</strong></em>
</p>

你甚至还可以直接根据这些内容一键生成相应的PPT。同样，对于会议，你可以让AI对会议内容进行总结并在会议结束后直接抄送给所有与会方。

<p align="center">
    <img src="/assets/images/2023-03-25/6.gif" alt="drawing"/>
    <br/><em><strong>根据文档自动生成PPT</strong></em>
</p>

Copilot X是基于Github的自动化工具，它可以帮助程序员更高效的工作（或者失业）。比如它能通过文字输入生成代码，修复已有程序的bug，自动生成相关文档，自动生成测试代码等。这些功能可以极大程度提升程序员的生产力，以及让程序员不用再花时间做他们觉得枯燥的事情，比如文档和测试。
不是很确定这几个工具到底是让人们在工作中划水更容易还是失业更容易。

<p align="center">
    <img src="/assets/images/2023-03-25/7.gif" alt="drawing"/>
    <br/><em><strong>聊天式编程</strong></em>
</p>

ChatGPT插件可以认为是Toolformer的产品化。它使得ChatGPT可以直接根据人的指令进行调用外部工具具体的行动，比如利用搜索引擎回答实时性信息的问题，调用外部知识库，甚至帮你点外卖。

<p align="center">
    <img src="/assets/images/2023-03-25/8.gif" alt="drawing"/>
    <br/><em><strong>ChatGPT插件系统</strong></em>
</p>

# 对底层变革的理解
看到人工智能在短短2个月就如此进展神速，可能很多人觉得很慌。有些能力出众的人也有抵触情绪。

## 不要做新时代的John Henry
John Henry的故事是一个美国民间传说。John是一个技艺精湛的铁路工人。当时，铁路建设非常艰苦，需要大量的人力和物力。有一天，铁路公司引进了一台新型蒸汽钻机，可以在短时间内完成大量的工作。

由于这台机器的出现，铁路公司开始裁员，许多工人失去了工作。John决定与这台蒸汽钻机进行比赛，他相信自己的力量可以胜过机器。比赛开始后，John不停地挥动他的铁锤，不断地敲打着岩石，每一次都比蒸汽钻机快得多。尽管他在比赛中取得了胜利，但这场比赛使他身心俱疲，不久之后便去世了。同时，比赛的胜利也并没有阻止机器替代人类修铁路的进程。

<p align="center">
    <img src="/assets/images/2023-03-25/9.gif" alt="drawing"/>
    <br/><em><strong>动画片：John Henry与蒸汽机比赛铆接铁路</strong></em>
</p>

这个故事被视为人与机器之间的斗争的象征。现在它也可以被视为人与人工智能工具之间的关系的一个寓言。即使一个人具有极高的技能和天赋，他的能力也没法被大家复制。从群体的角度看，这个群体也可能会在与机器的竞争中失败。

<p align="center">
    <img src="/assets/images/2023-03-25/10.gif" alt="drawing"/>
    <br/><em><strong>把John换成这只狗也许故事的走向就不一样了</strong></em>
</p>

在人工智能迅速发展的时代，这个故事提醒我们，我们不要去做工具已经可以做到的事情。人类应该意识到自己的长处，并利用自己的独特能力来与机器协作，以实现更大的价值和创造力。

## 认知方式的改变
记得以前读研究生时，导师教导我们要成为知识库，而不是成为数据库。意为让我们掌握事物之间的联系，而不是对知识死记硬背。在之后的很多年我也一直遵循这一原则。
当初建立这个公众号的目的是为了加强自己的认知。文章中其中很大一部分是我的读书感想。以前学习的方式是我一本本书去读并且记笔记，并且自己构建知识体系。现在人工智能自己可以成为知识库了，这样的学习方式似乎显得有些过时了。

<p align="center">
    <img src="/assets/images/2023-03-25/11.png" alt="drawing"/>
    <br/><em><strong>在notion中手动整理的读书笔记，虽然有用，但耗时耗力</strong></em>
</p>

我现在仍在思考进一步提升认知效率的方法论。以下想法还比较初级，不过这里可以简单分享下。

# 与时俱进，而不是站在变革的对立面
## 君子使物，不为物使
人区别于动物的一大特点就是善于创造并使用工具。现在我们创造出了这么强大的工具，自然是要好好使用它们。

<p align="center">
    <img src="/assets/images/2023-03-25/12.gif" alt="drawing"/>
    <br/><em><strong>电影《2001太空漫游》剧照：从人类第一次使用工具到探索星辰大海</strong></em>
</p>

比如我们可以把自己从一个做事的人转变为一个谋事的人。**让自己成为目标的制定者而不是执行者，这必须升级自己的思维往更高更抽象处走。**

在“使物”的同时我们还要注意不要被“物使”。在《[关于GPT，人工智能，以及人的一些思考](https://yxjiang.github.io/philosophy/ai/human-and-ai/)》我们讨论到，语言模型的一大问题是一本正经的胡说八道（现在一个通用的说法是Hallucination）。**模型质量的提升可以减少这种错误的发生几率，但同时是的这种错误更难以被发觉。**

人的认知偏差中有一种称为“认知惯性”的现象，是指人在思考和判断时，往往会依赖已有的知识、经验和想法，而对新的信息按照自己的偏好进行脑补。它可能使得人难以识别语言模型中的hallucination。当前99次语言模型都给出了正确的回答后，那么第100次回答就让会让人产生相信的偏好。接着脑补便发生了。

在我们大量使用人工智能工具节省解决问题的时间的同时，我们需要额外多花时间去验证人工智能给出的解决方案的正确性。这也许是人们将来的主要精力消耗所在。

## 成为绝对的领域专家
这里对专家的要求不是精通自己领域的现有知识，而是可以在这个领域里产生底层的新知识。

成为绝对的领域专家也许是个伪建议，因为绝大多数人不愿也无法成为顶级专家。而且这也许是一条与人工智能竞争而不是共处的路。不过就目前人工智能的进展来说，即使是一般的领域专家也很难被替代。

## 成为清楚描述问题的人
成为能够清楚描述问题的人的目的是为了更好地使用人工智能。我们可以逐渐发现，解决问题的方法已经逐渐从具体的执行转变为指导人工智能去完成了。使用语言模型的门槛很低，会打字就行。但是要利用好语言模型则需要再prompt engineering（提示工程）。能力强的人可以把GPT-3用成GPT-4，而能力差的人会把GPT-4用成GPT-3。

## 成为解决问题的架构师
有了人工智能的帮忙，并不代表我们每个人都可以解决更大更复杂的问题。虽然执行层面的效率可以成倍提升，但如果我们对人工智能瞎指挥，仍然成不了事。

我们需要训练的能力，是把一个复杂的问题量化并拆解成小问题。然后把每个小问题丢给人工智能去实现。之后再通过量化的方式来评估问题解决的质量。同时反馈给人工智能进行改进。
关于量化复杂问题的能力，我们可以看看《[新工具论-现代科学方法论的代表作](https://yxjiang.github.io/summary/world%20view/philosophy/%E6%96%B0%E5%B7%A5%E5%85%B7%E8%AE%BA-%E7%8E%B0%E4%BB%A3%E7%A7%91%E5%AD%A6%E6%96%B9%E6%B3%95%E8%AE%BA%E7%9A%84%E4%BB%A3%E8%A1%A8%E4%BD%9C/)》。而关于问题拆解的能力，我们可以看看《[谈谈《谈谈方法》](https://yxjiang.github.io/summary/book/philosophy/methodology/%E8%B0%88%E8%B0%88%E8%B0%88%E8%B0%88%E6%96%B9%E6%B3%95/)》。

## 和语言模型进行苏格拉底式的个性对话

语言模型具有广博的知识和强大的理解能力，我们可以利用它来完善自己。了解具体的知识只是第一步。对于吸收新知识，我们不仅要知道这个知识是什么，还要知道这个知识的来龙去脉，同时还要知道这个知识点和其他知识的联系。此外，为了验证自己吸收知识的水平，还可以让语言模型反过来考察自己。

<p align="center">
    <img src="/assets/images/2023-03-25/13.png" alt="drawing"/>
    <br/><em><strong>把新知识融入到已有的知识体系中</strong></em>
</p>

<p align="center">
    <img src="/assets/images/2023-03-25/14.png" alt="drawing"/>
    <br/><em><strong>我让ChatGPT考察我偏正短语的使用</strong></em>
</p>


相关文章
[更强的人工智能：GPT-4抢先用户测评](https://yxjiang.github.io/ai/gpt4/)
[让我们来做一个流浪地球中的MOSS](https://yxjiang.github.io/ai/moss/)
[关于GPT，人工智能，以及人的一些思考](https://yxjiang.github.io/philosophy/ai/human-and-ai/)
[新工具论-现代科学方法论的代表作](https://yxjiang.github.io/summary/world%20view/philosophy/%E6%96%B0%E5%B7%A5%E5%85%B7%E8%AE%BA-%E7%8E%B0%E4%BB%A3%E7%A7%91%E5%AD%A6%E6%96%B9%E6%B3%95%E8%AE%BA%E7%9A%84%E4%BB%A3%E8%A1%A8%E4%BD%9C/)
[从苏格拉底的对话看西方世界观与价值观](https://yxjiang.github.io/summary/book/philosophy/five-dialogs/)
[谈谈《谈谈方法》](https://yxjiang.github.io/summary/book/philosophy/methodology/%E8%B0%88%E8%B0%88%E8%B0%88%E8%B0%88%E6%96%B9%E6%B3%95/)